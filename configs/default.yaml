seed: 0
batch_size: 1
dataloader_num_workers: 4
resolution: 512
dataset_name: render

scale_destination_composite_to_minus_one_to_one: true
conditioning_channels: 11
# can't use xformers' attention because it doesn't output the intermediate attention maps
enable_xformers_memory_efficient_attention: false # TODO: true?
feed_empty_prompt: true

conditioning_maps: ['depth', 'normal', 'diffuse', 'mask', 'shading']
dataset_dir: ${oc.env:SCRATCH}/control_eval/rendered_2024-10-20_19-07-58_control
bg_estimates_dir: ${oc.env:SCRATCH}/compositing-outputs/WACV_bg_estimates
pretrained_model_name_or_path: ${oc.env:HF_HUB_CACHE}/models--stabilityai--stable-diffusion-2-1/snapshots/5cae40e6a2745ae2b01ad92ae5043f95f23644d6

aug:
  fill_value: -1

eval:
  run_name: ""
  start_batch: 0
  num_inference_steps: 20
  use_rgb_as_diffuse: false
  

  shading_maskout_mode: PointCloud
  # shading_maskout_mode: Cone
  shading_maskout_bbox_dilation: 30
  shading_maskout_bbox_depth_range: 4.0
  # shading_maskout_pc_type: absolute
  # shading_maskout_pc_range: 0.8
  shading_maskout_pc_type: relative
  shading_maskout_obj_dilation: 3
  shading_maskout_cone_radius: 0.6
  point_cloud_fov: 50
  # shading_maskout_pc_above_cropping_type: abovebbox
  shading_maskout_pc_above_cropping_type: argmin
  shading_maskout_cone_angle: 90


  device: cuda
  weight_dtype: fp16
  # predictor_names: [depthanythingv2_relative, precompute_stablenormal, precompute]
  predictor_names: [zoedepth, precompute_stablenormal, precompute]
  # predictor_names: [zoedepth, omnidata, dfnet]
  post_compositing: false
  # results_dir: ${oc.env:SCRATCH}/results/${now:%Y-%m-%d_%H-%M-%S}
  results_dir: ${oc.env:SCRATCH}/results
  shading_maskout_pc_range_relative: 0.5 # TODO: validate value
  forced_shading_mask_mode: override # override or combine
  controlnet_model_name_or_path: ${oc.env:SCRATCH}/openrooms_wo_bg_eccv/checkpoints/checkpoint-808000
  controlnet_model_name_or_path_inv: ${oc.env:LOCAL_SCRATCH}/sdi/.cache/checkpoints_inv/checkpoint-270000

  controlnet_conditioning_scale: 1.0
  guidance_scale: 0.0
  guess_mode: false

  use_relighting_guidance: true
  relighting_guidance_scale: 3.0
  relighting_guidance_rescale: 0.0 # same as in the Common diffusion ... paper
  relight_outside_shadow: false
  relight_outside_shadow_dilation: 0

  obj_mask_dilation_shadowcomp: 1

  relight_bg: false
  relight_bg_no_obj_for_post_comp: false

  use_coarse_shadow_as_is: false
  sd_edit_cleanup_percentage: 0.0 # max = 1.0

  shadow_guidance_mode: latent_blending # latent_blending # rgb_gradient

  shadow_uncertainty_enabled: false

  infill_shadow: true
  
  generate_images_for_post_compositing: true
  negative_sample_type: opposite_azimuth # opposite_azimuth, sh_auto, zerocomp
  shadow_opacity: 1.0
  latent_mask_weight: 0.05
  latent_mask_edge_boost: 2.0
  dilate_shadow_backbone: kornia
  light_radius: 1.0
  light_distance: 10.0

  output_shadow_comp_intermediate_images: true
  output_zero_comp_intrinsics: true

  render_only_gt_dir: false
  render_zerocomp_only: false

  force_metallic_value: null
  force_roughness_value: null
  force_albedo_value: null
