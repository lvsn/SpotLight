# General
cache_dir: null
seed: 0
push_to_hub: false
hub_token: null
hub_model_id: null
# Model
conditioning_channels: 11
feed_empty_prompt: true
scale_destination_composite_to_minus_one_to_one: true
use_predictors_instead_of_gt: false
# Load model
use_controlnet_xs: false
noise_scheduler_name: ddim
pretrained_model_name_or_path: ${oc.env:HF_HUB_CACHE}/models--stabilityai--stable-diffusion-2-1/snapshots/5cae40e6a2745ae2b01ad92ae5043f95f23644d6
# pretrained_model_name_or_path: stabilityai/stable-diffusion-2-1
controlnet_model_name_or_path: null
revision: null
tokenizer_name: null
vae_type: normal
# Train
num_train_epochs: 10
max_train_steps: null
# Checkpointing
checkpointing_steps: 2000
checkpoints_total_limit: 30
resume_from_checkpoint: null
# Optimizer
learning_rate: 8e-5
scale_lr: false
lr_scheduler: constant
lr_warmup_steps: 500
lr_num_cycles: 1
lr_power: 1.0
use_8bit_adam: false
dataloader_num_workers: 8
adam_beta1: 0.9
adam_beta2: 0.999
adam_weight_decay: 1e-2
adam_epsilon: 1e-08
max_grad_norm: 1.0
# Performance
gradient_accumulation_steps: 1
gradient_checkpointing: false
mixed_precision: null
allow_tf32: false
enable_xformers_memory_efficient_attention: true
set_grads_to_none: true
dynamo_backend: null
# dynamo_backend: INDUCTOR
# Dataset
dataset_name: lsun
dataset_dir: ../datasets/lsun_s
dataset_config_name: null
image_column: image
conditioning_image_column: conditioning_image
caption_column: text
max_train_samples: null
proportion_empty_prompts: 0
resolution: 512
train_batch_size: 4
val_batch_size: 16
# Augmentation
valid_mask_type: depth_valid_mask_loss
random_cutout_intrinsics: false

cutout_sphere_kwargs:
  fov: 60
  min_distance: 0.7
  max_distance: 2.0
  min_minkowski_distance: 0.8
  max_minkowski_distance: 2.5
  rotate_points: true
  anisotropic: true

aug:
  type: '3d' # 2d, 3d, 3d_bounding_rect
  max_holes: 3
  max_height: 0.9
  max_width: 0.9
  min_holes: 1
  min_height: 0.2
  min_width: 0.2
  fill_value: -1
  p: 0.6 # probability of applying the transform, when always_apply is False
  fully_drop_p: 0.4 # probability of dropping the whole image, when always_apply is False
  always_apply: true
  max_circles: 3
  min_circles: 1
  max_radius: 0.3
  min_radius: 0.05
  p_circle: 0.6
aug_diffuse:
  active: false
  max_holes: 1
  max_height: 0.5
  max_width: 0.5
  p: 0.2 # probability of applying the transform, when always_apply is False
# Loss scale
scale_loss_bg: 1.0
scale_loss_fg: 0.5
# Logging
report_to: comet_ml
output_dir: outputs/${now:%Y-%m-%d_%H-%M-%S}
logging_dir: logs
checkpoint_dir: checkpoints
val_scheduler:
  name: ddim
  kwargs:
    timestep_spacing: 'trailing'
    rescale_betas_zero_snr: true
validation_prompt: null
validation_image: null
num_validation_images: 4
validation_steps: 1000
# Tracker
tracker_project_name: controlnet
hydra:
  run:
    dir: outputs/${now:%Y-%m-%d_%H-%M-%S}
  sweep:
    dir: multirun/${now:%Y-%m-%d_%H-%M-%S}
  job:
    chdir: False

light_control:
  enabled: true


light_parametrization: 'light_bounding_box_3d' # light_bounding_box_2d, light_bounding_box_3d, spherical_harmonics_2d, spherical_harmonics_3d
sh_parametrization_normalize: true
controlnet_no_light: true
force_training_step: 500 # or null

changed_model_architecture: false

controlnet_init_kwargs:
  conditioning_channels: ${conditioning_channels}
  # projection_class_embeddings_input_dim: 320
  # class_embed_type: projection
  light_parametrization: null

eval:
  device: cuda
  weight_dtype: fp16
  num_inference_steps: 20
  controlnet_model_name_or_path: checkpoints/openrooms_ddim_2024-04-05_10-51-44/checkpoint-866000
  light_estimation_path: model_checkpoints/light_estimator/2024-05-06_18-57-12/checkpoints/light-estim-epoch=04-step=000256.ckpt
  results_dir: results/${now:%Y-%m-%d_%H-%M-%S}
  use_rgb_as_diffuse: false
  depth_scale_factor: 1.0
  obj_color_balance: true
  # shading_maskout_mode: BBox
  # shading_maskout_mode: BBoxWithDepth
  shading_maskout_mode: PointCloud
  shading_maskout_bbox_dilation: 30
  shading_maskout_bbox_depth_range: 2.5
  shading_maskout_pc_range: 0.6
  shading_maskout_pc_range_relative: 1.0
  # shading_maskout_pc_above_cropping_type: abovebbox
  shading_maskout_pc_above_cropping_type: argmin
  shading_maskout_obj_dilation: 10
  post_compositing: true
  output_all: true

controlnet_requires_grad: false
diffusion_loss_scale: 0.0
light_estimation_loss_scale: 0.01

light_estimation:
  type: 'controlnet_mlp' # controlnet_mlp, convnext
  output_dir: model_checkpoints/light_estimator/${now:%Y-%m-%d_%H-%M-%S}
  backbone_name_or_path: facebook/convnext-small-224
  learning_rate: 1e-3

  
  bins_per_dim: 100
  dims: 3

  use_controlnet: true
  controlnet_path: ${oc.env:SCRATCH}/checkpoint-592000/

  model_kwargs:
    detach_controlnet_features: true
    bins_per_dim: ${light_estimation.bins_per_dim}
    dims: ${light_estimation.dims}
    hidden_size: 768
    num_layers: 1
    res_sample_idx: 12
    use_bins: false
    use_gap: false    

  train_dataloader_kwargs:
    batch_size: 8
    num_workers: 1
    shuffle: true
    drop_last: true
  
  val_dataloader_kwargs:
    batch_size: 8
    num_workers: 1
    shuffle: false
    drop_last: true

  trainer_kwargs:
    num_sanity_val_steps: 2
    max_epochs: -1
    default_root_dir: ${light_estimation.output_dir}
  
  checkpoint_callback_kwargs:
    every_n_train_steps: 32
    save_top_k: -1
    dirpath: ${light_estimation.output_dir}/checkpoints
    filename: light-estim-{epoch:02d}-{step:06d}

  discretize_kwargs:
    min_value: -10
    max_value: 10
    bins_per_dim: ${light_estimation.bins_per_dim}

